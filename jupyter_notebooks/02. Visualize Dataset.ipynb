{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize Dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* The objective is to predict bike rental usage based on inputs such as temperature, humidity, wind speed... etc. \n",
    "\n",
    "## Inputs\n",
    "\n",
    "* instant: record index\n",
    "* dteday : date\n",
    "* season : season (1:springer, 2:summer, 3:fall, 4:winter)\n",
    "* yr : year (0: 2011, 1:2012)\n",
    "* mnth : month ( 1 to 12)\n",
    "* hr : hour (0 to 23)\n",
    "* holiday : wether day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "* weekday : day of the week\n",
    "* workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "* weathersit :\n",
    "    1. Clear, Few clouds, Partly cloudy\n",
    "    2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "    3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "    4. Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "* temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "* hum: Normalized humidity. The values are divided to 100 (max)\n",
    "* windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* cnt: count of total rental bikes including both casual and registered  \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "* Data Reference:\n",
    "\n",
    "This Hadi Fanaee-T\n",
    "Laboratory of Artificial Intelligence and Decision Support (LIAAD), University of Porto INESC Porto, Campus da FEUP Rua Dr. Roberto Frias, 378 4200 - 465 Porto, Portugal \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow==2.2.0\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv('inputs/datasets/raw/bike_sharing_daily.csv')\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(bike.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = bike.drop(labels= ['instant'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = bike.drop(labels= ['casual', 'registered'], axis = 1)\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.dteday = pd.to_datetime(bike.dteday, format= '%m/%d/%Y')\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike.index = pd.DatetimeIndex(bike.dteday)\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = bike.drop(labels= ['dteday'], axis=1)\n",
    "bike"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print out the Weekly Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CtnWeekly():\n",
    "    bike['cnt'].asfreq('W').plot(linewidth = 3)\n",
    "    plt.title('Bike Usage Per week')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Bike Rental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CtnWeekly()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bike usage per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike['cnt'].asfreq('M').plot(linewidth = 3)\n",
    "plt.title('Bike Usage Per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Bike Rental')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bike usage Per Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike['cnt'].asfreq('Q').plot(linewidth = 3)\n",
    "plt.title('Bike Usage Per Quarter')\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Bike Rental')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise the entire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(bike)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Divide Data into Numerical and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = bike[['temp', 'hum', 'windspeed', 'cnt']]\n",
    "\n",
    "sns.pairplot(X_numerical, diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distribution(var_data):\n",
    "    fig,ax = plt.subplots(1,2,figsize=(8, 8))\n",
    "    \n",
    "    ax[0].hist(var_data, bins=100)\n",
    "    ax[0].set_xlabel('Frequency')\n",
    "\n",
    "    mean_val = var_data.mean()\n",
    "    median_val = var_data.median()\n",
    "    min_val = var_data.min()\n",
    "    max_val =  var_data.max()\n",
    "    mode_val = var_data.mode()[0]\n",
    "\n",
    "    ax[0].axvline(mean_val, color = 'magenta' , linestyle='dashed', linewidth = 2)\n",
    "    ax[0].axvline(median_val, color = 'black' , linestyle='dashed', linewidth = 2)\n",
    "\n",
    "    ax[1].boxplot(var_data, vert=False)\n",
    "    ax[1].set_xlabel('value')\n",
    "\n",
    "    fig.suptitle(var_data.name)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_numerical:\n",
    "    show_distribution(X_numerical[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Catagorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = bike[['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build boxplot of all categorical variables againt the target variable 'cnt' \n",
    "* to see how each of the predictor variable stackup against the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x = 'season', y = 'cnt', data = bike)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x = 'mnth', y = 'cnt', data = bike)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x = 'weathersit', y = 'cnt', data = bike)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x = 'holiday', y = 'cnt', data = bike)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x = 'weekday', y = 'cnt', data = bike)\n",
    "plt.subplot(2,3,6)\n",
    "sns.boxplot(x = 'workingday', y = 'cnt', data = bike)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check categorical variables frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_cat:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    cat_count = bike[col].value_counts().sort_index()\n",
    "    cat_count.plot.bar(x=col,y='Rentals')\n",
    "    ax.set_title(col + ' counts')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Rentals')    \n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Use Correlation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find correlation between numerical variables with label using scatter charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_numerical:\n",
    "    correlation_value = bike[col].corr(bike['cnt'])\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    plt.scatter(x=bike[col],y=bike['cnt'], color='steelblue')\n",
    "    plt.title(\"correlation_value: \" + str(correlation_value))\n",
    "    plt.xlabel(col) \n",
    "    plt.ylabel(\"Rentals\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing categorical features with rentals cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_numerical:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    bike.boxplot(column='cnt', by=col, ax=ax)\n",
    "    ax.set_title('Label by ' + col)\n",
    "    ax.set_ylabel(\"Bike Rentals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_numerical.corr(), annot =True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **CREATE TRAINING AND TESTING DATASET**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bike[['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'hum', 'windspeed']].values\n",
    "y = bike['cnt'].values\n",
    "\n",
    "\n",
    "print(f'Features: {X[:5]}, \\nLabels: {y[:5]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Divide data into 70% for Training and 30% for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 0)\n",
    "print (f'X_train: {X_train.shape} \\nX_test: {X_test.shape} \\ny_train: {y_train.shape} \\ny_test: {y_test.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear Regression\n",
    "* Fit the linear regression on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(f'Predicted labels: {np.round(predictions)[:10]}')\n",
    "print(f'Actual labels: {y_test[:10]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualizing a scatter plot that compares the predictions to the actual labels. \n",
    "* Overlay a trend line to get a general sense for how well the predicted labels align with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, … 0.\n",
    "\n",
    "p = np.poly1d(z) # Define the polynimial function\n",
    "print(f'Polynomial function: {p}')\n",
    "plt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the Model using MSE, RMSE, R<sup>2</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'MSE: {mse}')\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear Algorithm**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the regression model by using a Lasso algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit Lasso model on training set\n",
    "model = Lasso().fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# Evaluate the model using text data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'MSE: {mse}')\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, … 0.\n",
    "p = np.poly1d(z) # Define the polynimial function\n",
    "print(f'Polynomial function: {p}')\n",
    "plt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Fit decistion tree model on training set alos known as model training\n",
    "model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# Visualize the model tree\n",
    "tree = export_text(model)\n",
    "print(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluate the Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'MSE: {mse}')\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, … 0.\n",
    "p = np.poly1d(z) # Define the polynimial function\n",
    "print(f'Polynomial function: {p}')\n",
    "plt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ensemble Algorithm**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Ensemble Algorithm to improve over the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'MSE: {mse}')\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, … 0.\n",
    "p = np.poly1d(z) # Define the polynimial function\n",
    "print(f'Polynomial function: {p}')\n",
    "plt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trying a boosting ensemble algorithm for good measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Fit a lasso model on the training set\n",
    "model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'MSE: {mse}')\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1) # Fit the polynomial of degree 1 to the points (y_test, predictions). Returns a vector of coefficients z that minimises the squared error in the order deg, deg-1, … 0.\n",
    "p = np.poly1d(z) # Define the polynimial function\n",
    "print(f'Polynomial function: {p}')\n",
    "plt.plot(y_test,p(y_test), color='magenta') # Here  p(y_test) will evaluate the polynomial function for every point in y_test\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Optimize Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "# Use a Gradient Boosting algorithm\n",
    "alg = GradientBoostingRegressor()\n",
    "\n",
    "# Try these hyperparameter values\n",
    "params = {\n",
    " 'learning_rate': [0.1, 0.5, 1.0],\n",
    " 'n_estimators' : [50, 100, 150]\n",
    " }\n",
    "\n",
    "# Find the best hyperparameter combination to optimize the R2 metric\n",
    "score = make_scorer(r2_score)\n",
    "gridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "model=gridsearch.best_estimator_\n",
    "print(model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "numeric_features = [6,7,8,9]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them)\n",
    "categorical_features = [0,1,2,3,4,5]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', GradientBoostingRegressor())])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check how the model performs with the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try an alternative algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a different estimator in the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', RandomForestRegressor())])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Display metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions - Preprocessed')\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Use the Trained Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = 'bike-share.pkl'\n",
    "joblib.dump(model, './inputs/datasets/raw/bike-share.pkl') # Save it at ./inputs/datasets/raw/bike-share.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and predict labels for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = joblib.load('./inputs/datasets/raw/bike-share.pkl')\n",
    "\n",
    "# Create a numpy array containing a new observation (for example tomorrow's seasonal and weather forecast information)\n",
    "X_new = np.array([[1,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]).astype('float64')\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Use the model to predict tomorrow's rentals\n",
    "result = loaded_model.predict(X_new)\n",
    "print('Prediction: {:.0f} rentals'.format(np.round(result[0])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suppose you have a weather forecast for the next five days; you could use the model to predict bike rentals for each day based on the expected weather conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An array of features based on five-day weather forecast\n",
    "X_new = np.array([[0,1,1,0,0,1,0.344167,0.363625,0.805833,0.160446],\n",
    "                  [0,1,0,1,0,1,0.363478,0.353739,0.696087,0.248539],\n",
    "                  [0,1,0,2,0,1,0.196364,0.189405,0.437273,0.248309],\n",
    "                  [0,1,0,3,0,1,0.2,0.212122,0.590435,0.160296],\n",
    "                  [0,1,0,4,0,1,0.226957,0.22927,0.436957,0.1869]])\n",
    "\n",
    "# Use the model to predict rentals\n",
    "results = loaded_model.predict(X_new)\n",
    "print('5-day rental predictions:')\n",
    "for prediction in results:\n",
    "    print(np.round(prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "  os.makedirs(name='outputs/datasets/collection') # create here your folder\n",
    "  # os.makedirs(name='')\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "\n",
    "bike.to_csv(f\"outputs/datasets/collection/bike_sharing_daily.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
